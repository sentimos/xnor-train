{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Introduction\n",
    "This tutorial shows how to use tensorflow to train a neural network to mimic the $\\neg (x_1 \\oplus x_2)$ function. This function, abbreviated as XNOR, returns 1 only if $x_1$ is equal to $x_2$. The values are summarized in the table below:\n",
    "\n",
    "$$\n",
    "\\begin{array}{c|c|c}\n",
    "x_1 & x_2 & y \\\\ \\hline\n",
    "0 & 0 & 1 \\\\\n",
    "0 & 1 & 0 \\\\\n",
    "1 & 0 & 0 \\\\\n",
    "1 & 1 & 1 \\\\\n",
    "\\end{array}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def CreateLayer(X, width):\n",
    "    W = tf.get_variable(\"W\", [X.get_shape()[1].value, width], tf.float32)\n",
    "    b = tf.get_variable(\"b\", [width], tf.float32)\n",
    "    return tf.nn.sigmoid(tf.add(tf.matmul(X, W), b))\n",
    "\n",
    "def CreateTrainigOp(model, learning_rate, labels):\n",
    "    loss_op = tf.reduce_mean(tf.square(tf.subtract(model, labels)))\n",
    "    train_op = tf.train.AdamOptimizer(learning_rate).minimize(loss_op)\n",
    "    return train_op, loss_op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained. Session saved in /tmp/xnor.ckpt\n"
     ]
    }
   ],
   "source": [
    "g = tf.Graph()\n",
    "\n",
    "with g.as_default():\n",
    "  # Placeholders are fed data from the outside\n",
    "  X = tf.placeholder(tf.float32, [None, 2], name=\"X\")\n",
    "  y = tf.placeholder(tf.float32, [None, 1], name=\"y\")\n",
    "\n",
    "  # A neural network consisting of two layers. The first layer\n",
    "  # takex X, multiplies by weights W, adds biases b and applies\n",
    "  # sigmoid function to produce z0. This is repeated for layer 2\n",
    "  # except now z0 plays the role of the input. We use variable\n",
    "  # scope to make weights and biases for both layers unique.\n",
    "  with tf.variable_scope(\"layer1\"):\n",
    "      z0 = CreateLayer(X, 2)\n",
    "  with tf.variable_scope(\"layer2\"):\n",
    "      z1 = CreateLayer(z0, 1)\n",
    "  with tf.variable_scope(\"xnor\"):\n",
    "      training_op, loss_op = CreateTrainigOp(z1, 0.03, y) \n",
    "  init_op = tf.global_variables_initializer()\n",
    "  saver = tf.train.Saver()\n",
    "\n",
    "# The summary writer is going to be used to trace loss, output from the first\n",
    "# layer (z0) and output from the second layer (z1)\n",
    "writer = tf.summary.FileWriter(\"/tmp/xnor_log\", g)\n",
    "loss_summ = tf.summary.scalar(\"loss\", loss_op)\n",
    "\n",
    "# The input on which NN is trained. For, say [0, 0], we expect the NN to\n",
    "# output something close to [1], etc.\n",
    "X_train = np.array([[0, 0], [0, 1], [1, 0], [1, 1],])\n",
    "y_train = np.array([[1], [0], [0], [1]])\n",
    "\n",
    "sess = tf.Session(graph=g)\n",
    "sess.run(init_op)\n",
    "for step in xrange(5000):\n",
    "    feed_dict = {X: X_train, y: y_train}\n",
    "    sess.run(training_op, feed_dict=feed_dict)\n",
    "    if step % 10 == 0:\n",
    "        writer.add_summary(\n",
    "            sess.run(loss_summ, feed_dict=feed_dict), step)\n",
    "save_path = saver.save(sess, '/tmp/xnor.ckpt')\n",
    "sess.close()\n",
    "print \"Model trained. Session saved in\", save_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
